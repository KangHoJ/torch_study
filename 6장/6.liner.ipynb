{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.optim as optim\n",
    "torch.set_printoptions(edgeitems=2, linewidth=75)\n",
    "t_c = [[0.5,  14.0], [15.0,11.0], [28.0, 11.0],  [8.0,  3.0], [-4.0,  6.0], [13.0, 21.0]]\n",
    "t_u = [[35.7,33.1], [55.9, 58.2], [81.9, 56.3], [48.9, 33.9], [21.8, 48.4], [60.4, 68.4]]\n",
    "t_c = torch.tensor(t_c) # <1>\n",
    "t_u = torch.tensor(t_u)# <1>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([6, 2])"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t_c.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[4.8900, 3.3900],\n",
       "         [6.0400, 6.8400],\n",
       "         [8.1900, 5.6300],\n",
       "         [2.1800, 4.8400],\n",
       "         [3.5700, 3.3100]]),\n",
       " tensor([[5.5900, 5.8200]]))"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "n_samples = t_u.shape[0]\n",
    "n_val = int(0.2 * n_samples)\n",
    "\n",
    "shuffled_indices = torch.randperm(n_samples)\n",
    "\n",
    "train_indices = shuffled_indices[:-n_val]\n",
    "val_indices = shuffled_indices[-n_val:]\n",
    "\n",
    "t_u_train = t_u[train_indices]\n",
    "t_c_train = t_c[train_indices]\n",
    "\n",
    "t_u_val = t_u[val_indices]\n",
    "t_c_val = t_c[val_indices]\n",
    "\n",
    "t_un_train = 0.1 * t_u_train\n",
    "t_un_val = 0.1 * t_u_val\n",
    "\n",
    "t_un_train , t_un_val"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(Parameter containing:\n",
       " tensor([[ 0.0147, -0.3985]], requires_grad=True),\n",
       " Parameter containing:\n",
       " tensor([0.7005], requires_grad=True))"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch.nn as nn\n",
    "linear_model = nn.Linear(2, 1) # 입력 피처2 , 출력 피처1 을 가진 nn.Linear 인스턴스 생성\n",
    "linear_model(t_un_val)\n",
    "linear_model.weight , linear_model.bias"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Parameter containing:\n",
       " tensor([[-0.0896,  0.4661],\n",
       "         [ 0.2957,  0.0953]], requires_grad=True),\n",
       " Parameter containing:\n",
       " tensor([0.3779, 0.2452], requires_grad=True)]"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t_c = [0.5,  14.0, 15.0, 28.0, 11.0,  8.0,  3.0, -4.0,  6.0, 13.0, 21.0]\n",
    "t_u = [35.7, 55.9, 58.2, 81.9, 56.3, 48.9, 33.9, 21.8, 48.4, 60.4, 68.4]\n",
    "t_c = torch.tensor(t_c).unsqueeze(1) # 10*1\n",
    "t_u = torch.tensor(t_u).unsqueeze(1) # 10*1\n",
    "\n",
    "linear_model = nn.Linear(2, 2) # 입력피처1 , 출력피처1\n",
    "optimizer = optim.SGD(linear_model.parameters(),lr=1e-2)\n",
    "\n",
    "list(linear_model.parameters()) # init생성자에 정의된 서브 모듈까지 재귀적으로 호출하며 만나는 모든 파마리터 리스트를 담은 리스트"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Linear(in_features=2, out_features=2, bias=True)"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "linear_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "def training_loop(n_epochs, optimizer, model, loss_fn, t_u_train, t_u_val,t_c_train, t_c_val):\n",
    "    for epoch in range(1, n_epochs + 1):\n",
    "        t_p_train = model(t_u_train) # <1>\n",
    "        loss_train = loss_fn(t_p_train, t_c_train)\n",
    "\n",
    "        t_p_val = model(t_u_val) # <1>\n",
    "        loss_val = loss_fn(t_p_val, t_c_val)\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        loss_train.backward() # <2>\n",
    "        optimizer.step()\n",
    "\n",
    "        if epoch == 1 or epoch % 1000 == 0:\n",
    "            print(f\"Epoch {epoch}, Training loss {loss_train.item():.4f},\"\n",
    "                  f\" Validation loss {loss_val.item():.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1, Training loss 141.8551, Validation loss 113.5386\n",
      "Epoch 1000, Training loss 15.7817, Validation loss 10.4365\n",
      "Epoch 2000, Training loss 13.6056, Validation loss 9.0250\n",
      "Epoch 3000, Training loss 13.0500, Validation loss 8.4199\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(Parameter containing:\n",
       " tensor([[ 5.2724, -0.3279],\n",
       "         [ 0.0117,  2.8768]], requires_grad=True),\n",
       " Parameter containing:\n",
       " tensor([-15.3951,  -2.8375], requires_grad=True))"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "training_loop(\n",
    "    n_epochs = 3000, \n",
    "    optimizer = optimizer,\n",
    "    model = linear_model,\n",
    "    loss_fn = nn.MSELoss(), # <1>\n",
    "    t_u_train = t_un_train,\n",
    "    t_u_val = t_un_val, \n",
    "    t_c_train = t_c_train,\n",
    "    t_c_val = t_c_val)\n",
    "\n",
    "linear_model.weight , linear_model.bias"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Sequential(\n",
       "  (0): Linear(in_features=1, out_features=13, bias=True)\n",
       "  (1): Tanh()\n",
       "  (2): Linear(in_features=13, out_features=1, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch.nn as nn\n",
    "seq_model2 = nn.Sequential(\n",
    "    nn.Linear(1,13),\n",
    "    nn.Tanh(),\n",
    "    nn.Linear(13,1)\n",
    ")\n",
    "seq_model2\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.weight Parameter containing:\n",
      "tensor([[ 0.4678],\n",
      "        [-0.1260],\n",
      "        [-0.2810],\n",
      "        [ 0.7049],\n",
      "        [ 0.3439],\n",
      "        [ 0.4722],\n",
      "        [-0.7408],\n",
      "        [ 0.5509],\n",
      "        [-0.1674],\n",
      "        [ 0.7639],\n",
      "        [ 0.5701],\n",
      "        [ 0.6725],\n",
      "        [ 0.1320]], requires_grad=True) torch.Size([13, 1])\n",
      "0.bias Parameter containing:\n",
      "tensor([-0.0222,  0.2186, -0.3544, -0.0907,  0.8263, -0.5409,  0.4232,\n",
      "         0.2743, -0.0480,  0.2576,  0.7402,  0.7180, -0.9278],\n",
      "       requires_grad=True) torch.Size([13])\n",
      "2.weight Parameter containing:\n",
      "tensor([[-0.1877,  0.0069,  0.2000, -0.0582, -0.1776,  0.1916, -0.0504,\n",
      "          0.0743, -0.1032, -0.1246,  0.0963,  0.2261, -0.0381]],\n",
      "       requires_grad=True) torch.Size([1, 13])\n",
      "2.bias Parameter containing:\n",
      "tensor([0.0278], requires_grad=True) torch.Size([1])\n"
     ]
    }
   ],
   "source": [
    "for name , params in seq_model2.named_parameters():\n",
    "    print(name , params , params.shape) # 처음에는 임의의 값 배정"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Sequential(\n",
       "  (hidden_linear): Linear(in_features=3, out_features=10, bias=True)\n",
       "  (hidden_activation): Tanh()\n",
       "  (output_linear): Linear(in_features=10, out_features=3, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from collections import OrderedDict\n",
    "seq_model = nn.Sequential(OrderedDict([\n",
    "    ('hidden_linear', nn.Linear(2, 10)),\n",
    "    ('hidden_activation', nn.Tanh()),\n",
    "    ('output_linear', nn.Linear(10, 2))\n",
    "]))\n",
    "\n",
    "seq_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(Parameter containing:\n",
       " tensor([ 0.1201,  0.2730,  0.3547,  0.5108, -0.4209, -0.4567,  0.2949,\n",
       "         -0.2065, -0.2110, -0.2667], requires_grad=True),\n",
       " torch.Size([10]),\n",
       " Parameter containing:\n",
       " tensor([[ 0.2081, -0.5624,  0.0811],\n",
       "         [ 0.2154, -0.2787, -0.2539],\n",
       "         [ 0.2454,  0.5625, -0.5195],\n",
       "         [ 0.5112, -0.2309, -0.0689],\n",
       "         [ 0.3663, -0.4153,  0.3244],\n",
       "         [-0.0218,  0.4839,  0.5064],\n",
       "         [-0.0578, -0.2637,  0.0118],\n",
       "         [ 0.1861, -0.3329,  0.4281],\n",
       "         [ 0.3326, -0.1494, -0.0889],\n",
       "         [-0.2621,  0.2971,  0.4496]], requires_grad=True),\n",
       " torch.Size([10, 3]))"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "seq_model.hidden_linear.bias , seq_model.hidden_linear.bias.shape , seq_model.hidden_linear.weight , seq_model.hidden_linear.weight.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(Parameter containing:\n",
       " tensor([0.1020], requires_grad=True),\n",
       " torch.Size([1]),\n",
       " Parameter containing:\n",
       " tensor([[-0.2180,  0.1208,  0.1115,  0.1197,  0.1042, -0.0606,  0.1916,\n",
       "          -0.0764, -0.1128, -0.3003]], requires_grad=True),\n",
       " torch.Size([1, 10]))"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "seq_model.output_linear.bias , seq_model.output_linear.bias.shape , seq_model.output_linear.weight , seq_model.output_linear.weight.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'seq_model' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[7], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m optimizer \u001b[38;5;241m=\u001b[39m optim\u001b[38;5;241m.\u001b[39mSGD(\u001b[43mseq_model\u001b[49m\u001b[38;5;241m.\u001b[39mparameters(), lr\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1e-3\u001b[39m) \u001b[38;5;66;03m# <1>\u001b[39;00m\n\u001b[0;32m      3\u001b[0m training_loop(\n\u001b[0;32m      4\u001b[0m     n_epochs \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m5000\u001b[39m, \n\u001b[0;32m      5\u001b[0m     optimizer \u001b[38;5;241m=\u001b[39m optimizer, \n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     10\u001b[0m     t_c_train \u001b[38;5;241m=\u001b[39m t_c_train,\n\u001b[0;32m     11\u001b[0m     t_c_val \u001b[38;5;241m=\u001b[39m t_c_val)\n\u001b[0;32m     13\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124moutput\u001b[39m\u001b[38;5;124m'\u001b[39m, seq_model(t_un_val))\n",
      "\u001b[1;31mNameError\u001b[0m: name 'seq_model' is not defined"
     ]
    }
   ],
   "source": [
    "optimizer = optim.SGD(seq_model.parameters(), lr=1e-3) # <1>\n",
    "\n",
    "training_loop(\n",
    "    n_epochs = 5000, \n",
    "    optimizer = optimizer, \n",
    "    model = seq_model,\n",
    "    loss_fn = nn.MSELoss(),\n",
    "    t_u_train = t_un_train,\n",
    "    t_u_val = t_un_val, \n",
    "    t_c_train = t_c_train,\n",
    "    t_c_val = t_c_val)\n",
    "    \n",
    "print('output', seq_model(t_un_val))\n",
    "print('answer', t_c_val)\n",
    "# print('hidden', seq_model.hidden_linear.weight.grad)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pyto",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
