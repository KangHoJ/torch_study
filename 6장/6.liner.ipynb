{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.optim as optim\n",
    "torch.set_printoptions(edgeitems=2, linewidth=75)\n",
    "t_c = [0.5,  14.0, 15.0, 28.0, 11.0,  8.0,  3.0, -4.0,  6.0, 13.0, 21.0]\n",
    "t_u = [35.7, 55.9, 58.2, 81.9, 56.3, 48.9, 33.9, 21.8, 48.4, 60.4, 68.4]\n",
    "t_c = torch.tensor(t_c).unsqueeze(1) # <1>\n",
    "t_u = torch.tensor(t_u).unsqueeze(1) # <1>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[6.0400],\n",
       "         [5.8200],\n",
       "         [4.8900],\n",
       "         [6.8400],\n",
       "         [4.8400],\n",
       "         [3.5700],\n",
       "         [5.6300],\n",
       "         [5.5900],\n",
       "         [2.1800]]),\n",
       " tensor([[3.3900],\n",
       "         [8.1900]]))"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "n_samples = t_u.shape[0]\n",
    "n_val = int(0.2 * n_samples)\n",
    "\n",
    "shuffled_indices = torch.randperm(n_samples)\n",
    "\n",
    "train_indices = shuffled_indices[:-n_val]\n",
    "val_indices = shuffled_indices[-n_val:]\n",
    "\n",
    "t_u_train = t_u[train_indices]\n",
    "t_c_train = t_c[train_indices]\n",
    "\n",
    "t_u_val = t_u[val_indices]\n",
    "t_c_val = t_c[val_indices]\n",
    "\n",
    "t_un_train = 0.1 * t_u_train\n",
    "t_un_val = 0.1 * t_u_val\n",
    "\n",
    "t_un_train , t_un_val"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(Parameter containing:\n",
       " tensor([[-0.5830]], requires_grad=True),\n",
       " Parameter containing:\n",
       " tensor([0.3171], requires_grad=True))"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch.nn as nn\n",
    "linear_model = nn.Linear(1, 1) # 입력 피처1 , 출력 피처1 을 가진 nn.Linear 인스턴스 생성\n",
    "linear_model(t_un_val)\n",
    "linear_model.weight , linear_model.bias"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-0.2659],\n",
       "        [-0.2659],\n",
       "        [-0.2659],\n",
       "        [-0.2659],\n",
       "        [-0.2659],\n",
       "        [-0.2659],\n",
       "        [-0.2659],\n",
       "        [-0.2659],\n",
       "        [-0.2659],\n",
       "        [-0.2659]], grad_fn=<AddmmBackward0>)"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = torch.ones(10,1) # nn에 잇는 모든 모듈은 한번에 여러 입력을 가진 매치에 대한 출력을 만들도록 작성 \n",
    "linear_model(x)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Parameter containing:\n",
       " tensor([[-0.0444]], requires_grad=True),\n",
       " Parameter containing:\n",
       " tensor([-0.4086], requires_grad=True)]"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t_c = [0.5,  14.0, 15.0, 28.0, 11.0,  8.0,  3.0, -4.0,  6.0, 13.0, 21.0]\n",
    "t_u = [35.7, 55.9, 58.2, 81.9, 56.3, 48.9, 33.9, 21.8, 48.4, 60.4, 68.4]\n",
    "t_c = torch.tensor(t_c).unsqueeze(1) # 10*1\n",
    "t_u = torch.tensor(t_u).unsqueeze(1) # 10*1\n",
    "\n",
    "linear_model = nn.Linear(1, 1) # 입력피처1 , 출력피처1\n",
    "optimizer = optim.SGD(linear_model.parameters(),lr=1e-2)\n",
    "\n",
    "list(linear_model.parameters()) # init생성자에 정의된 서브 모듈까지 재귀적으로 호출하며 만나는 모든 파마리터 리스트를 담은 리스트"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "def training_loop(n_epochs, optimizer, model, loss_fn, t_u_train, t_u_val,t_c_train, t_c_val):\n",
    "    for epoch in range(1, n_epochs + 1):\n",
    "        t_p_train = model(t_u_train) # <1>\n",
    "        loss_train = loss_fn(t_p_train, t_c_train)\n",
    "\n",
    "        t_p_val = model(t_u_val) # <1>\n",
    "        loss_val = loss_fn(t_p_val, t_c_val)\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        loss_train.backward() # <2>\n",
    "        optimizer.step()\n",
    "\n",
    "        if epoch == 1 or epoch % 1000 == 0:\n",
    "            print(f\"Epoch {epoch}, Training loss {loss_train.item():.4f},\"\n",
    "                  f\" Validation loss {loss_val.item():.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1, Training loss 154.0337, Validation loss 420.2544\n",
      "Epoch 1000, Training loss 4.3387, Validation loss 10.1400\n",
      "Epoch 2000, Training loss 2.8633, Validation loss 5.1968\n",
      "Epoch 3000, Training loss 2.7436, Validation loss 4.7359\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(Parameter containing:\n",
       " tensor([[5.2465]], requires_grad=True),\n",
       " Parameter containing:\n",
       " tensor([-17.0517], requires_grad=True))"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "training_loop(\n",
    "    n_epochs = 3000, \n",
    "    optimizer = optimizer,\n",
    "    model = linear_model,\n",
    "    loss_fn = nn.MSELoss(), # <1>\n",
    "    t_u_train = t_un_train,\n",
    "    t_u_val = t_un_val, \n",
    "    t_c_train = t_c_train,\n",
    "    t_c_val = t_c_val)\n",
    "\n",
    "linear_model.weight , linear_model.bias"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Sequential(\n",
       "  (0): Linear(in_features=1, out_features=13, bias=True)\n",
       "  (1): Tanh()\n",
       "  (2): Linear(in_features=13, out_features=1, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch.nn as nn\n",
    "seq_model2 = nn.Sequential(\n",
    "    nn.Linear(1,13),\n",
    "    nn.Tanh(),\n",
    "    nn.Linear(13,1)\n",
    ")\n",
    "seq_model2\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.weight Parameter containing:\n",
      "tensor([[-0.3874],\n",
      "        [-0.7413],\n",
      "        [-0.8002],\n",
      "        [-0.2198],\n",
      "        [ 0.3769],\n",
      "        [ 0.3937],\n",
      "        [ 0.6255],\n",
      "        [ 0.9311],\n",
      "        [-0.4350],\n",
      "        [ 0.2844],\n",
      "        [-0.0528],\n",
      "        [ 0.8863],\n",
      "        [-0.5240]], requires_grad=True) torch.Size([13, 1])\n",
      "0.bias Parameter containing:\n",
      "tensor([ 0.4774, -0.3199, -0.5489, -0.0896,  0.5627,  0.9168,  0.7239,\n",
      "         0.5349, -0.7586, -0.1637,  0.9310, -0.7483,  0.1741],\n",
      "       requires_grad=True) torch.Size([13])\n",
      "2.weight Parameter containing:\n",
      "tensor([[-0.0897, -0.2093, -0.2384,  0.0468, -0.2190, -0.2327,  0.1066,\n",
      "         -0.0152,  0.0748,  0.0870,  0.2360, -0.1212, -0.1435]],\n",
      "       requires_grad=True) torch.Size([1, 13])\n",
      "2.bias Parameter containing:\n",
      "tensor([0.1347], requires_grad=True) torch.Size([1])\n"
     ]
    }
   ],
   "source": [
    "for name , params in seq_model2.named_parameters():\n",
    "    print(name , params , params.shape) # 처음에는 임의의 값 배정"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Sequential(\n",
       "  (hidden_linear): Linear(in_features=1, out_features=10, bias=True)\n",
       "  (hidden_activation): Tanh()\n",
       "  (output_linear): Linear(in_features=10, out_features=1, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from collections import OrderedDict\n",
    "seq_model = nn.Sequential(OrderedDict([\n",
    "    ('hidden_linear', nn.Linear(1, 10)),\n",
    "    ('hidden_activation', nn.Tanh()),\n",
    "    ('output_linear', nn.Linear(10, 1))\n",
    "]))\n",
    "\n",
    "seq_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(Parameter containing:\n",
       " tensor([ 0.6921,  0.9266, -0.4149,  0.1226,  0.0189,  0.2917,  0.7501,\n",
       "          0.2849,  0.1488,  0.6043], requires_grad=True),\n",
       " torch.Size([10]),\n",
       " Parameter containing:\n",
       " tensor([[-0.8984],\n",
       "         [ 0.6960],\n",
       "         [-0.3153],\n",
       "         [-0.0466],\n",
       "         [-0.0333],\n",
       "         [-0.4494],\n",
       "         [ 0.0464],\n",
       "         [-0.4921],\n",
       "         [-0.3113],\n",
       "         [ 0.4602]], requires_grad=True),\n",
       " torch.Size([10, 1]))"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "seq_model.hidden_linear.bias , seq_model.hidden_linear.bias.shape , seq_model.hidden_linear.weight , seq_model.hidden_linear.weight.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(Parameter containing:\n",
       " tensor([0.2412], requires_grad=True),\n",
       " torch.Size([1]),\n",
       " Parameter containing:\n",
       " tensor([[ 0.1916,  0.2202,  0.0426,  0.1614, -0.0426,  0.0640,  0.2522,\n",
       "           0.2314,  0.1024, -0.1974]], requires_grad=True),\n",
       " torch.Size([1, 10]))"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "seq_model.output_linear.bias , seq_model.output_linear.bias.shape , seq_model.output_linear.weight , seq_model.output_linear.weight.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1, Training loss 144.4363, Validation loss 402.2155\n",
      "Epoch 1000, Training loss 3.9826, Validation loss 41.2819\n",
      "Epoch 2000, Training loss 2.5164, Validation loss 24.6535\n",
      "Epoch 3000, Training loss 1.9607, Validation loss 17.5083\n",
      "Epoch 4000, Training loss 2.5127, Validation loss 10.8832\n",
      "Epoch 5000, Training loss 1.9951, Validation loss 10.6527\n",
      "output tensor([[-0.6002],\n",
      "        [24.0103]], grad_fn=<AddmmBackward0>)\n",
      "answer tensor([[ 3.],\n",
      "        [28.]])\n"
     ]
    }
   ],
   "source": [
    "optimizer = optim.SGD(seq_model.parameters(), lr=1e-3) # <1>\n",
    "\n",
    "training_loop(\n",
    "    n_epochs = 5000, \n",
    "    optimizer = optimizer,\n",
    "    model = seq_model,\n",
    "    loss_fn = nn.MSELoss(),\n",
    "    t_u_train = t_un_train,\n",
    "    t_u_val = t_un_val, \n",
    "    t_c_train = t_c_train,\n",
    "    t_c_val = t_c_val)\n",
    "    \n",
    "print('output', seq_model(t_un_val))\n",
    "print('answer', t_c_val)\n",
    "# print('hidden', seq_model.hidden_linear.weight.grad)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pyto",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
