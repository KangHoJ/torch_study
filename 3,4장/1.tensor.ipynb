{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([1., 1., 1.])\n",
      "torch.Size([3])\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import matplotlib.pyplot as plt\n",
    "a = torch.ones(3) # 크기가 3인 1차원 텐서\n",
    "print(a)\n",
    "print(a.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[4., 1., 3.],\n",
      "        [5., 3., 3.],\n",
      "        [2., 1., 3.]])\n",
      "torch.Size([3, 3])\n",
      "tensor(1.)\n"
     ]
    }
   ],
   "source": [
    "points = torch.tensor([[4.0, 1.0 ,3], [5.0, 3.0,3], [2.0, 1.0,3]])\n",
    "print(points)\n",
    "print(points.shape) \n",
    "print(points[0,1])                                                                                                                         "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[-1.6958e+00,  2.3777e-01,  3.8842e-01,  2.7796e-01,  2.2868e-01,\n",
       "          -2.6154e-01],\n",
       "         [ 7.0473e-01,  1.1601e+00,  8.0190e-02, -4.0737e-01,  4.7210e-01,\n",
       "           8.3322e-01],\n",
       "         [ 6.5348e-01,  6.7286e-01,  7.2607e-01, -4.2413e-01, -5.4338e-01,\n",
       "           4.2493e-01],\n",
       "         [-2.5316e-01,  3.6846e-01, -9.2816e-01,  3.5734e-02, -9.9915e-01,\n",
       "           7.5915e-01],\n",
       "         [-1.5289e-01, -1.7803e-01, -2.6959e-01,  1.1033e+00, -5.2463e-01,\n",
       "          -5.4542e-01]],\n",
       "\n",
       "        [[ 1.1953e+00,  1.9227e+00,  1.6895e+00, -2.3116e-01, -3.7591e-04,\n",
       "           6.9854e-01],\n",
       "         [ 1.9997e+00, -3.6545e-01,  1.5327e+00, -3.6427e-01, -3.5198e-01,\n",
       "           1.6524e+00],\n",
       "         [ 9.7517e-02, -2.9272e-01, -3.0911e-01, -2.9190e-01, -4.2896e-01,\n",
       "           6.2179e-01],\n",
       "         [-2.5018e+00, -1.2892e+00,  1.1763e-01, -7.3423e-01,  8.8597e-01,\n",
       "           2.6264e-01],\n",
       "         [ 4.6836e-01,  4.2559e-01,  7.2875e-03, -3.1958e-02,  1.7152e+00,\n",
       "          -1.9976e+00]],\n",
       "\n",
       "        [[ 4.0213e-01,  1.2410e+00,  1.0628e+00,  1.3257e-01, -4.3583e-01,\n",
       "           1.6821e+00],\n",
       "         [ 5.9353e-01,  3.1078e-01, -2.5686e-01, -4.4389e-01,  1.5428e+00,\n",
       "           9.2676e-01],\n",
       "         [-1.9725e+00, -4.9888e-01,  4.6191e-01, -8.8682e-01, -8.5591e-02,\n",
       "          -1.6661e+00],\n",
       "         [-5.8091e-01, -4.5826e-01, -2.6516e-01, -1.0202e+00,  2.2286e-02,\n",
       "           1.5419e+00],\n",
       "         [ 2.2850e-03,  4.1198e-01, -2.3040e-01, -4.1236e-01,  1.1331e+00,\n",
       "          -2.9070e-03]]])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "image = torch.randn(3,5,6) # 3채널(색) , 5행 , 6열\n",
    "image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([3, 5, 6])"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "image.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[-0.0328,  1.1338,  1.0469,  0.0598, -0.0692,  0.7064],\n",
      "        [ 1.0993,  0.3685,  0.4520, -0.4052,  0.5543,  1.1375],\n",
      "        [-0.4072, -0.0396,  0.2930, -0.5343, -0.3526, -0.2065],\n",
      "        [-1.1120, -0.4597, -0.3586, -0.5729, -0.0303,  0.8546],\n",
      "        [ 0.1059,  0.2198, -0.1642,  0.2197,  0.7746, -0.8486]])\n",
      "torch.Size([5, 6])\n"
     ]
    }
   ],
   "source": [
    "print(image.mean(-3)) # 채널에 관해서 평균 구함 (1,1)값 평균 = 0.0039 , (1,2)값 평균 = -0.1465  \n",
    "print(image.mean(-3).shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[-0.1487,  0.4522, -0.0006,  0.1171, -0.2733,  0.2421],\n",
      "        [ 0.2518,  0.0802,  0.6076, -0.3307,  0.3640,  0.2476],\n",
      "        [-0.3111,  0.2013,  0.1545, -0.5261,  0.4354,  0.4964]])\n",
      "torch.Size([3, 6])\n"
     ]
    }
   ],
   "source": [
    "print(image.mean(-2)) # 각 행값들의 평균을 구해서 넣어준다(세로 연산)\n",
    "print(image.mean(-2).shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[-0.1374,  0.4738,  0.2516, -0.1695, -0.0945],\n",
      "        [ 0.8791,  0.6839, -0.1006, -0.5432,  0.0978],\n",
      "        [ 0.6808,  0.4455, -0.7747, -0.1267,  0.1503]])\n",
      "torch.Size([3, 5])\n"
     ]
    }
   ],
   "source": [
    "print(image.mean(-1)) # 각 열값들의 평균을 구해서 넣어준다 (가로 연산)\n",
    "print(image.mean(-1).shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[[1]],\n",
      "\n",
      "        [[1]],\n",
      "\n",
      "        [[1]]])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "torch.Size([3, 1, 1])"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "weights = torch.tensor([[1],[1],[1]]).unsqueeze(-1) # 가장 오른쪽차원 추가 [3,1] -> [3,1,1]\n",
    "print(weights)\n",
    "weights.shape "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[ 5.7833e-01,  2.7625e-01,  1.8477e+00,  1.6780e+00, -1.2982e-01,\n",
       "           6.3216e-01],\n",
       "         [ 3.9858e-01, -3.8918e-01,  8.1343e-01,  6.7158e-01, -4.1242e-01,\n",
       "          -2.8699e-01],\n",
       "         [-8.8036e-01, -2.9735e-01,  5.3853e-02, -1.3739e+00,  6.7856e-01,\n",
       "           3.0225e-01],\n",
       "         [-5.9437e-01,  6.2562e-01,  2.9757e-01,  2.4109e-01,  1.4217e+00,\n",
       "           1.2525e-02],\n",
       "         [-1.3218e+00, -8.4334e-01,  1.7185e+00,  3.2919e-01, -7.1972e-01,\n",
       "          -4.4764e-01]],\n",
       "\n",
       "        [[ 1.6842e-01, -1.6902e+00, -1.3217e-01,  9.0236e-01,  8.5405e-01,\n",
       "           1.6585e+00],\n",
       "         [ 1.0030e+00, -1.8466e-01, -1.3355e+00,  3.4179e-01, -1.2985e-01,\n",
       "           1.4332e+00],\n",
       "         [-1.5220e-01,  1.3967e+00,  6.7098e-01,  6.4261e-01,  2.9226e-01,\n",
       "           3.3068e-01],\n",
       "         [ 1.8295e-03, -1.0449e+00, -4.0328e-01, -2.1275e+00,  1.4109e+00,\n",
       "           2.8605e-01],\n",
       "         [-2.8711e-01, -1.9110e+00,  5.6878e-01,  4.7600e-01, -1.1532e+00,\n",
       "          -7.4790e-01]],\n",
       "\n",
       "        [[-7.3492e-01,  9.7445e-01,  6.9997e-01, -1.1499e+00,  1.4275e+00,\n",
       "           5.9161e-01],\n",
       "         [ 1.1608e+00, -7.6486e-01,  3.4949e-01,  2.2130e+00,  1.7418e+00,\n",
       "          -5.9396e-01],\n",
       "         [-1.0646e+00, -5.8406e-01, -4.2754e-01, -1.0012e+00,  6.1960e-01,\n",
       "           9.6104e-01],\n",
       "         [-5.9795e-01,  1.0040e+00,  2.2176e-01, -3.2588e-01,  1.4994e+00,\n",
       "          -4.2708e-01],\n",
       "         [ 1.2357e+00, -2.4166e+00, -2.3241e-01, -1.0472e+00, -1.4835e-01,\n",
       "          -1.1094e+00]]])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "image * weights # [3,1,1] * [3,5,6] / [3,5,6] * [3,5,6]은 가능하나 / [3,2,1] * [3,5,6]은 연산이 불가능하다"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "원본 텐서 이름: ('channels',)\n",
      "수정된 텐서 이름: ('rows',)\n"
     ]
    }
   ],
   "source": [
    "# 차원 이름 지정하기\n",
    "img_names = torch.tensor([0.1, 0.2, 0.5], names=['channels'])  # 채널 이름 지정\n",
    "print(\"원본 텐서 이름:\", img_names.names)\n",
    "\n",
    "# 텐서 이름 수정\n",
    "re_img_names = img_names.rename(channels='rows')  # 올바른 차원 이름을 사용하여 수정\n",
    "print(\"수정된 텐서 이름:\", re_img_names.names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(('channels', 'rows', 'columns'), torch.Size([3, 5, 5]))"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "img_t = torch.randn(3, 5, 5) \n",
    "img_named =  img_t.refine_names(..., 'channels', 'rows', 'columns')\n",
    "img_named.names , img_named.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[1., 1.],\n",
       "         [1., 1.],\n",
       "         [1., 1.]]),\n",
       " torch.Size([3, 2]),\n",
       " tensor([[1., 1., 1.],\n",
       "         [1., 1., 1.]]),\n",
       " torch.Size([2, 3]))"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 형태 변경 \n",
    "a = torch.ones(3,2)\n",
    "a_t = a.transpose(0,1)\n",
    "a , a.shape , a_t, a_t.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0., 0.],\n",
       "        [0., 0.],\n",
       "        [0., 0.]])"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 변환\n",
    "a = torch.ones(3,2)\n",
    "a.zero_() # 입력된 모든 텐서의 요스를 0으로 바꿈\n",
    "a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       " 4\n",
       " 5\n",
       " 3\n",
       " 4\n",
       " 2\n",
       " 1\n",
       "[torch.storage.TypedStorage(dtype=torch.int64, device=cpu) of size 6]"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## 저장 공간 확인 \n",
    "points = torch.tensor([[4,5],[3,4],[2,1]])\n",
    "points.storage() # 저장이 어떻게 되는지 확인 (실제로는 크기가6인 배열공간) = 차원에 무관하게 실제 저장 공간 레이아웃은 1차원"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[4, 5],\n",
       "         [3, 4],\n",
       "         [2, 1]]),\n",
       " tensor([[ 4,  5],\n",
       "         [10,  4],\n",
       "         [ 2,  1]]))"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 복제 방법\n",
    "points = torch.tensor([[4,5],[3,4],[2,1]])\n",
    "second_point = points[1].clone() # 복제 \n",
    "second_point[0] = 10\n",
    "points\n",
    "\n",
    "# 복제 x(동일한 저장공간을 가리킴)\n",
    "points2 = torch.tensor([[4,5],[3,4],[2,1]])\n",
    "second_point2 = points2[1]\n",
    "second_point2[0] = 10\n",
    "\n",
    "points , points2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([5, 4, 3]), (1, 5, 20))"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 전치 연산 \n",
    "some_t = torch.ones(3,4,5)\n",
    "transpost_t = some_t.transpose(0,2)  # 0차원과 2차원 위치를 변경시킨다 \n",
    "transpost_t.shape , transpost_t.stride()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[1., 1., 1., 1., 1.],\n",
       "         [1., 1., 1., 1., 1.],\n",
       "         [1., 1., 1., 1., 1.],\n",
       "         [1., 1., 1., 1., 1.]],\n",
       "\n",
       "        [[1., 1., 1., 1., 1.],\n",
       "         [1., 1., 1., 1., 1.],\n",
       "         [1., 1., 1., 1., 1.],\n",
       "         [1., 1., 1., 1., 1.]],\n",
       "\n",
       "        [[1., 1., 1., 1., 1.],\n",
       "         [1., 1., 1., 1., 1.],\n",
       "         [1., 1., 1., 1., 1.],\n",
       "         [1., 1., 1., 1., 1.]]])"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "some_t.contiguous() # 인접한 텐서로 만들어줌(가끔 인접한 텐서에 대해서만 동작하는 경우가 있음 )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "## numpy배열로 변환\n",
    "t = torch.ones(3,4)\n",
    "t_np = t.numpy()\n",
    "t_torch = torch.from_numpy(t_np)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0, 1, 2],\n",
       "        [3, 4, 5],\n",
       "        [6, 7, 8]])"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 연습문제\n",
    "a = torch.tensor(list(range(9)))\n",
    "a = a.view(3,3)\n",
    "a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[4, 5],\n",
       "        [7, 8]])"
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "b = a[1:,1:]\n",
    "b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pyto",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
